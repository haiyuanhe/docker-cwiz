version: "2"

services:
  kerberos:
    image: cloudwiz/kerberos:1.0.0
    restart: always
    container_name: kerberos01
    hostname: kerberos01
    volumes: 
      - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
      - ${WORK_PATH}/kerberos:/kerberos
    environment:
      KERBEROS_PRIMARY: root zookeeper HTTP hdfs hbase kafka
      KERBEROS_HOST: zookeeper namenode datanode hbase-master hbase-regionserver kafka opentsdb
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.40

  namenode:
    image: cloudwiz/hadoop-namenode-kerberos:2.7.7
    container_name: namenode
    hostname: namenode
    restart: always
    ports:
      - "50070:50070"
    volumes:
      - ${WORK_PATH}/data/hadoop/dfs/name:/data/dfs/namenode
      - ${WORK_PATH}/logs/hadoop/:${WORK_PATH}/hadoop-2.7.7/logs
      - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
      - ${WORK_PATH}/kerberos:/kerberos
    environment:
      - CLUSTER_NAME=prod
    env_file:
      - ./hadoop.env
    extra_hosts:
      - "datanode:172.19.0.3"
      - "hbase-master:172.19.0.5"
      - "hbase-regionserver:172.19.0.6"
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.2
    depends_on:
      - kerberos

  datanode:
    image: cloudwiz/hadoop-datanode-kerberos:2.7.7
    container_name: datanode
    hostname: datanode
    restart: always
    volumes:
      - ${WORK_PATH}/data/hadoop/dfs/data:/data/dfs/datanode
      - ${WORK_PATH}/logs/hadoop/:${WORK_PATH}/hadoop-2.7.7/logs
      - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
      - ${WORK_PATH}/kerberos:/kerberos
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop.env
    extra_hosts:
      - "namenode:172.19.0.2"
      - "hbase-master:172.19.0.5"
      - "hbase-regionserver:172.19.0.6"
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.3
    depends_on:
      - namenode
      - kerberos

  zookeeper:
    image: cloudwiz/zookeeper-kerberos:3.4.10
    container_name: zookeeper
    hostname: zookeeper
    restart: always
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888
    volumes:
      - ${WORK_PATH}/data/zookeeper/:/data
      - ${WORK_PATH}/data/zookeeper/datalog:/datalog
      - ${WORK_PATH}/logs/zookeeper/:/logs/
      - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
      - ${WORK_PATH}/kerberos:/kerberos
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.4

  hbase-master:
    image: cloudwiz/hbase-master-kerberos:1.4.10
    container_name: hbase-master
    hostname: hbase-master
    restart: always
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 zookeeper:2181"
    ports:
      - "16010:16010"
    volumes:
      - ${WORK_PATH}/logs/hadoop/:${WORK_PATH}/hbase-1.4.10/logs
      - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
      - ${WORK_PATH}/kerberos:/kerberos
    extra_hosts: 
      - "namenode:172.19.0.2"
      - "datanode:172.19.0.3"
      - "zookeeper:172.19.0.4"
      - "hbase-regionserver:172.19.0.6"
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.5
    depends_on:
      - kerberos
      - namenode
      - datanode
      - zookeeper

  hbase-regionserver:
    image: cloudwiz/hbase-regionserver-kerberos:1.4.10
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    restart: always
    env_file:
      - ./hadoop.env
    environment:
      HBASE_CONF_hbase_regionserver_hostname: hbase-regionserver
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 zookeeper:2181 hbase-master:16010"
    ports:
      - "16030:16030"
    volumes:
      - ${WORK_PATH}/logs/hadoop/:${WORK_PATH}/hbase-1.4.10/logs
      - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
      - ${WORK_PATH}/kerberos:/kerberos
    extra_hosts:
      - "namenode:172.19.0.2"
      - "datanode:172.19.0.3"
      - "zookeeper:172.19.0.4"
      - "hbase-master:172.19.0.5"
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.6
    depends_on:
      - kerberos
      - namenode
      - datanode
      - zookeeper
      - hbase-master

  kafka:
    image: cloudwiz/kafka-kerberos:2.11-1.0.2
    container_name: kafka
    hostname: kafka
    restart: always
    env_file:
      - ./hadoop.env
    ports:
      - 9092:9092
    extra_hosts:
      - "zookeeper:172.19.0.4"
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.10
    environment:
      KAFKA_LISTENERS: SASL_PLAINTEXT://kafka:9092
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_LISTENERS: SASL_PLAINTEXT://kafka:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms128M" 
    volumes:
      - ${WORK_PATH}/data/kafka/:/kafka/kafka-logs-kafka/
      - ${WORK_PATH}/logs/kafka/:/opt/kafka_2.11-1.0.2/logs
      - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
      - ${WORK_PATH}/kerberos:/kerberos
    depends_on:
      - zookeeper

  # kafka:
  #   image: cloudwiz/kafka-kerberos:2.11-1.0.2
  #   container_name: kafka
  #   hostname: kafka
  #   restart: always
  #   env_file:
  #     - ./hadoop.env
  #   ports:
  #     - 9092:9092
  #   extra_hosts:
  #     - "zookeeper:172.19.0.4"
  #   networks:
  #     cwiz_network:
  #       ipv4_address: 172.19.0.10
  #   environment:
  #     KAFKA_LISTENERS: SASL_PLAINTEXT://kafka:9092,SSL://kafka:9093
  #     KAFKA_ADVERTISED_HOST_NAME: kafka
  #     KAFKA_ADVERTISED_LISTENERS: SASL_PLAINTEXT://kafka:9092,SSL://kafka:9093
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_HEAP_OPTS: "-Xmx256M -Xms128M"
  #     KAFKA_SSL_MECHANISM_INTER_BROKER_PROTOCOL: SSL
  #     KAFKA_ssl_enabled_mechanisms: SSL
  #     KAFKA_ssl_keystore_location: /certs/server.keystore.jks
  #     KAFKA_ssl_keystore_password: Cloudwiz_p0c
  #     KAFKA_ssl_key_password: Cloudwiz_p0c
  #     KAFKA_ssl_truststore_location: /certs/server.truststore.jks
  #     KAFKA_ssl_truststore_password: Cloudwiz_p0c
  #     KAFKA_ssl_client_auth: required
  #     # KAFKA_ssl_endpoint_identification_algorithm:
  #     KAFKA_ssl_enabled_protocols: TLSv1.2,TLSv1.1,TLSv1
  #     KAFKA_ssl_truststore_type: JKS
  #     KAFKA_ssl_keystore_type: JKS
  #   volumes:
  #     - ${WORK_PATH}/data/kafka/:/kafka/kafka-logs-kafka/
  #     - ${WORK_PATH}/logs/kafka/:/opt/kafka_2.11-1.0.2/logs
  #     - ${WORK_PATH}/etc/krb5.conf:/etc/krb5.conf
  #     - ${WORK_PATH}/kerberos:/kerberos
  #     - ${WORK_PATH}/certs:/certs
  #   depends_on:
  #     - zookeeper

  # opentsdb:
  #   image: cloudwiz/opentsdb-kerberos:2.3.0
  #   container_name: opentsdb
  #   hostname: opentsdb
  #   restart: always
  #   env_file:
  #   - ./hadoop.env
  #   networks:
  #     cwiz_network:
  #       ipv4_address: 172.19.0.12
  #   volumes:
  #   - ${WORK_PATH}/startup/envs.sh:${WORK_PATH}/startup/envs.sh
  #   - ${WORK_PATH}/opentsdb/bin/start.sh:${WORK_PATH}/opentsdb/bin/start.sh
  #   - ${WORK_PATH}/opentsdb/conf/opentsdb.conf:${WORK_PATH}/opentsdb/conf/opentsdb.conf
  #   - ${WORK_PATH}/opentsdb/conf/logback.xml:${WORK_PATH}/opentsdb/conf/logback.xml
  #   - ${WORK_PATH}/startup:${WORK_PATH}/startup
  #   - ${WORK_PATH}/logs/opentsdb/:${WORK_PATH}/logs/opentsdb/
  #   depends_on:
  #   - hbase-regionserver

  elasticsearch:
    image: elasticsearch:5.4.3
    container_name: elasticsearch
    hostname: elasticsearch
    restart: always
    ulimits:
      memlock:
        soft: -1
        hard: -1
    env_file:
    - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 zookeeper:2181 hbase-master:16010"
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
    volumes:
    - ${WORK_PATH}/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    - ${WORK_PATH}/data/elasticsearch/:/usr/share/elasticsearch/data/
    - ${WORK_PATH}/logs/elasticsearch/:/usr/share/elasticsearch/logs/
    - ${WORK_PATH}/certs/es/truststore.jks:/usr/share/elasticsearch/config/truststore.jks
    - ${WORK_PATH}/certs/es/node1-keystore.jks:/usr/share/elasticsearch/config/keystore.jks
    - ${WORK_PATH}/certs/es/sgadmins.keystore.jks:/usr/share/elasticsearch/plugins/search-guard-5/tools/sgadmin.keystore.jks
    networks:
      cwiz_network:
        ipv4_address: 172.19.0.8

volumes:
  hadoop_namenode: 
  hadoop_datanode: 
  elasticsearch:
  zookeeper:
  nginx:
  kafka:

networks:
  cwiz_network:
    ipam:
      driver: default
      config:
        - subnet: "172.19.0.0/24"
